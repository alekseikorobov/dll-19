{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.14.1-cp38-cp38-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/aleksei/.virtualenvs/ml/lib/python3.8/site-packages (from torchtext) (4.62.3)\n",
      "Requirement already satisfied: torch==1.13.1 in /home/aleksei/.virtualenvs/ml/lib/python3.8/site-packages (from torchtext) (1.13.1+cu116)\n",
      "Requirement already satisfied: numpy in /home/aleksei/.virtualenvs/ml/lib/python3.8/site-packages (from torchtext) (1.24.2)\n",
      "Requirement already satisfied: requests in /home/aleksei/.virtualenvs/ml/lib/python3.8/site-packages (from torchtext) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions in /home/aleksei/.virtualenvs/ml/lib/python3.8/site-packages (from torch==1.13.1->torchtext) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aleksei/.virtualenvs/ml/lib/python3.8/site-packages (from requests->torchtext) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/aleksei/.virtualenvs/ml/lib/python3.8/site-packages (from requests->torchtext) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aleksei/.virtualenvs/ml/lib/python3.8/site-packages (from requests->torchtext) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aleksei/.virtualenvs/ml/lib/python3.8/site-packages (from requests->torchtext) (2022.12.7)\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.14.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "-1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.vocab import vocab\n",
    "from collections import Counter, OrderedDict\n",
    "counter = Counter([\"a\", \"a\", \"b\", \"b\", \"b\"])\n",
    "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "v1 = vocab(ordered_dict)\n",
    "print(v1['a']) #prints 1\n",
    "# print(v1['out of vocab']) #raise RuntimeError since default index is not set\n",
    "tokens = ['e', 'd', 'c', 'b', 'a']\n",
    "#adding <unk> token and default index\n",
    "unk_token = '<unk>'\n",
    "default_index = -1\n",
    "v2 = vocab(OrderedDict([(token, 1) for token in tokens]), specials=[unk_token])\n",
    "v2.set_default_index(default_index)\n",
    "print(v2['<unk>']) #prints 0\n",
    "print(v2['out of vocab']) #prints -1\n",
    "#make default index same as index of unk_token\n",
    "v2.set_default_index(v2[unk_token])\n",
    "v2['out of vocab'] is v2[unk_token] #prints True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tch.shape=torch.Size([1, 100])\n",
      "['541']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1],\n",
       "        [1, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [4, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on = torch.ones((1,100),dtype=torch.int32)\n",
    "\n",
    "tch1 = torch.cat([on, tch])\n",
    "tch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "t = [1,2,3,4,0,0,0,0,0]\n",
    "\n",
    "g = itertools.takewhile(lambda l: l !=0, t)\n",
    "print(list(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> examples = ['chip', 'baby', 'Beautiful']\n",
    ">>> vec = text.vocab.GloVe(name='6B', dim=50)\n",
    ">>> ret = vec.get_vecs_by_tokens(examples, lower_case_backup=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "668ad5806631cec6ff425fd6065661de7ee73adb89f9f8ddbfdee9e4a1c4f075"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
