{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa223af88e0>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 3498.90it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from output/model_rec_text_best_scale_2/CRNN_LSTM_min_loss.pth\n",
      "len(dataset)=4\n",
      "txt_predict='from', txt_fact='from'\n",
      "txt_predict='select', txt_fact='select'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt_predict='*', txt_fact='*'\n",
      "txt_predict='[users]', txt_fact='[users]'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import MyDatasetRec\n",
    "import importlib\n",
    "importlib.reload(MyDatasetRec)\n",
    "from MyDatasetRec import MyDatasetRec\n",
    "from torch.utils.data import DataLoader\n",
    "from config_rec import all_alph\n",
    "import MyModelRec as my_model\n",
    "import torch\n",
    "from itertools import groupby\n",
    "from MyRecognizer import Recognizer\n",
    "        \n",
    "conf = {\n",
    "    'fonts':[\"example/TextBPNPlusPlus/dataset/MyGenerator/font.ttf\"],\n",
    "    'is_crop':[True],\n",
    "    #'texts':['#$%^&*()py','-=~!@#$%', '()_+[];','[users]','(users)'],\n",
    "    'texts':['select','*', 'from','[users]'],\n",
    "    'size_images':[(160 ,32)] #cnn_output_width * 16 + 2\n",
    "    , 'text_colors':['#000000']\n",
    "    , 'background_colors':['#ffffff']\n",
    "    , 'is_simple_text':[True]\n",
    "    , 'font_sizes':[22]\n",
    "    , 'is_scale':[True]\n",
    "    , 'scale_size':[(None, 32)]\n",
    "}\n",
    "\n",
    "dataset = MyDatasetRec([conf], all_alph)\n",
    "\n",
    "#model_path = 'output/model_rec_/CRNN_LSTM_v1_130.pth'\n",
    "#model_path = 'output/model_rec_text_best_scale/CRNN_LSTM_min_loss.pth'\n",
    "model_path = 'output/model_rec_text_best_scale_1/CRNN_LSTM_min_loss.pth'\n",
    "#model_path = 'output/model_rec_best/CRNN_LSTM_min_loss.pth'\n",
    "#model_path = 'output/model_rec_/CRNN_LSTM_v1_130.pth'\n",
    "model_path = 'output/model_rec_text_best_scale_2/CRNN_LSTM_min_loss.pth'\n",
    "rec = Recognizer(model_path, all_alph)\n",
    "\n",
    "def correct_chars(text:str):\n",
    "    \n",
    "    #{'>>;.^$\", txt_fact='#$%^&*()'\n",
    "    #\"@#|)\\\\{'>\", txt_fact='-=~!@#$%'\n",
    "    #'^$~:/<%', txt_fact='()_+[];'\n",
    "    \n",
    "    #@#|)\\\\{'>\", txt_fact='-=~!@#$%'\n",
    "    return text.replace('/','[')\\\n",
    "               .replace(':','+')\n",
    "\n",
    "print(f'{len(dataset)=}')\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "for im, l in loader:\n",
    "    #print(f'{im.shape },{l.shape}')\n",
    "    txt_predict = rec.get_text_from_image(im)\n",
    "    txt_fact = dataset.torch_text_dict.get_label(l[0])\n",
    "    \n",
    "    #txt_predict = correct_chars(txt_predict)\n",
    "    \n",
    "    print(f'{txt_predict=}, {txt_fact=}')\n",
    "    plt.imshow(im[0].permute(1,2,0).numpy())\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Необходимо сделать датасет из тех же картинок, которые были на обучении детекции\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_np.shape=(13, 32, 3)\n",
      "img1.shape=(32, 78, 3)\n",
      "torch.Size([3, 32, 500])\n",
      "torch.Size([1, 3, 32, 500])\n",
      "txt='string'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=78x32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.transforms import InterpolationMode\n",
    "import cv2\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image, ImageColor, ImageDraw, ImageFilter, ImageFont\n",
    "img_np = np.load(f'for_rec_data/image_test/example_image_{1}.npy','r')\n",
    "print(f'{img_np.shape=}')\n",
    "\n",
    "\n",
    "img1 = rec.image_resize(img_np, width = None, height = 32)\n",
    "\n",
    "print(f'{img1.shape=}')\n",
    "\n",
    "img2 = Image.fromarray(img1)\n",
    "\n",
    "img_tensor,_=dataset.transforms(img2,None)\n",
    "\n",
    "print(img_tensor.shape)\n",
    "img_tensor = img_tensor.unsqueeze(0)\n",
    "print(img_tensor.shape)\n",
    "\n",
    "txt = rec.get_text_from_image(img_tensor)\n",
    "print(f'{txt=}')\n",
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# распознование картинки из тренировочного набора\n",
    "# не доведено до конца!!!!!!\n",
    "\n",
    "from config_rec import all_alph,train_conf\n",
    "import MyGenerator.ImageGenerator as im\n",
    "import importlib\n",
    "importlib.reload(im)\n",
    "from MyGenerator.ImageGenerator import ImageGenerator\n",
    "from MyRecognizer import Recognizer\n",
    "import torchmetrics\n",
    "\n",
    "#model_path = 'output/model_rec_text_best_scale/CRNN_LSTM_min_loss.pth'\n",
    "\n",
    "#rec = Recognizer(model_path, all_alph)\n",
    "\n",
    "train_conf = [{\n",
    "    'fonts':['example/TextBPNPlusPlus/dataset/MyGenerator/font.ttf'],\n",
    "    'is_crop':[True]\n",
    "    , 'text_colors':['#2C6DBF']\n",
    "    , 'background_colors':['#1E1E1E']\n",
    "    , 'texts':\n",
    "        \n",
    "        # array[0:350]\n",
    "        #list(map(str,np.random.random_integers(100,100000,100)))\n",
    "        #['12345678901234567890123456789012345678901234567890'] #14 epoch\n",
    "        #['deletedresponsiblepersonid'] #477 epoch\n",
    "        [\n",
    "            '0',\n",
    "            '01',\n",
    "            '012',\n",
    "            '0123',\n",
    "            '01234',\n",
    "            '012345',\n",
    "            '0123456',\n",
    "            '01234567',\n",
    "            '012345678',\n",
    "            '0123456789',\n",
    "            '01234567890',\n",
    "            '012345678901',\n",
    "            '0123456789012',\n",
    "            '01234567890123',\n",
    "            '012345678901234',\n",
    "            '0123456789012345',\n",
    "            '01234567890123456',\n",
    "            '012345678901234567',\n",
    "            '0123456789012345678',\n",
    "            '01234567890123456789',\n",
    "            '012345678901234567890'\n",
    "         ] #407 epoch\n",
    "    ,\n",
    "    #'size_images':[((int(153/16)+1)*16 +2 ,18)] #for cnn_output_width = 19\n",
    "    'size_images':[(160 ,32)] #cnn_output_width * 16 + 2\n",
    "    , 'is_simple_text':[True]\n",
    "    , 'font_sizes':[13]\n",
    "    , 'is_scale':[True]\n",
    "    , 'scale_size':[(None, 32)]\n",
    "}]\n",
    "\n",
    "im_gen = ImageGenerator(train_conf)\n",
    "\n",
    "print(f'{im_gen.size=}')\n",
    "print(f'{im_gen.size_word=}')\n",
    "\n",
    "_,axs = plt.subplots(im_gen.size_word,figsize=(5*im_gen.size_word,10))\n",
    "\n",
    "\n",
    "model_path = 'output/model_rec_text_best_scale_1/CRNN_LSTM_min_loss.pth'\n",
    "rec = Recognizer(model_path, all_alph)\n",
    "\n",
    "for i in range(im_gen.size_word):\n",
    "    img,text = im_gen.get_by_word_index(i)\n",
    "    img_tensor,t = transform(img,None)\n",
    "    text_res = rec.get_text_from_image(img_tensor.unsqueeze(0))\n",
    "    print(f'{text=} {text_res=}')\n",
    "    axs[i].set_yticks([])\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #cer = torchmetrics.CharErrorRate()\n",
    "# #print(cer(text, 'abc56767') )\n",
    "\n",
    "\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь проверка на реальной картинке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image:np.ndarray, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt='get'\n",
      "txt='пchgnge>'\n",
      "txt='chenges'\n",
      "txt='{'\n",
      "txt='stuing'\n",
      "txt='lastuzl'\n",
      "txt='шsещйг;'\n",
      "txt='get'\n",
      "txt='pzqtected'\n",
      "txt=');'\n",
      "txt='o'\n",
      "txt='ueatedn;'\n",
      "txt='='\n",
      "txt='o'\n",
      "txt='виндт'\n",
      "txt='!'\n",
      "txt='оctng='\n",
      "txt='}'\n",
      "txt='login;'\n",
      "txt=':'\n",
      "txt='оежсвдиоnв-'\n",
      "txt='autuorgocenge'\n",
      "txt='{'\n",
      "txt='fnt'\n",
      "txt='есырtртmы-'\n",
      "txt='liferime;'\n",
      "txt='login;'\n",
      "txt='octng='\n",
      "txt='ochanges'\n",
      "txt='!'\n",
      "txt='тve'\n",
      "txt='{'\n",
      "txt=')}'\n",
      "txt='оеазрtрnы'\n",
      "txt='}'\n",
      "txt='{'\n",
      "txt='stuing'\n",
      "txt='session!nfo'\n",
      "txt='cueatedn'\n",
      "txt='тve'\n",
      "txt='пвинд'\n",
      "txt='ваseentity'\n",
      "txt='puotected'\n",
      "txt='sthing'\n",
      "txt='--'\n",
      "txt='}'\n",
      "txt='qautuorx'\n",
      "txt='sthing'\n",
      "txt='wetun'\n",
      "txt='!'\n",
      "txt='oreerenaes'\n",
      "txt='usедйр'\n",
      "txt='set'\n",
      "txt='{'\n",
      "txt='paterime'\n",
      "txt='togin'\n",
      "txt='wetun'\n",
      "txt='pzqtected'\n",
      "txt='пchgnge>'\n",
      "txt='public'\n",
      "txt='public'\n",
      "txt='last+ccessbate;'\n",
      "txt='etng='\n",
      "txt='qet'\n",
      "txt='ore=et-'\n",
      "txt='='\n",
      "txt='set'\n",
      "txt='login'\n",
      "txt=']'\n",
      "txt='pzotected'\n",
      "txt='шsедйр'\n",
      "txt='}'\n",
      "txt='pzotected'\n",
      "txt='sthing'\n",
      "txt='!'\n",
      "txt='set'\n",
      "txt='public'\n",
      "txt=']'\n",
      "txt='ueated0n'\n",
      "txt='vauue;'\n",
      "txt='paterime'\n",
      "txt='usezzp;'\n",
      "txt='тve'\n",
      "txt='vauue;'\n",
      "txt='иetuhn'\n",
      "txt='public'\n",
      "txt='paterime'\n",
      "txt='='\n",
      "txt='}'\n",
      "txt=');'\n",
      "txt='vauue;'\n",
      "txt='cvuass'\n",
      "txt='{'\n",
      "txt='}'\n",
      "txt='pgotected'\n",
      "txt='oreerenaes'\n",
      "txt='оetпz='\n",
      "txt='oreerenee>'\n",
      "txt='cueated0n;'\n",
      "txt='{'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import cv2\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image, ImageColor, ImageDraw, ImageFilter, ImageFont\n",
    "\n",
    "arr = os.listdir('for_rec_data/image_real')\n",
    "for file in arr:\n",
    "    img_np = np.load('for_rec_data/image_real/'+file,'r')\n",
    "    #print(f'{img_np.shape=}')\n",
    "    img1 = image_resize(img_np, width = None, height = 32)\n",
    "    #print(f'{img1.shape=}')\n",
    "    img2 = Image.fromarray(img1)\n",
    "    img_tensor,_=dataset.transforms(img2,None)\n",
    "    #print(img_tensor.shape)\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "    #print(img_tensor.shape)\n",
    "    txt = rec.get_text_from_image(img_tensor)\n",
    "    print(f'{txt=}')\n",
    "    #img2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for file in arr:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
